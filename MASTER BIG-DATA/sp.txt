
Why spark
Hadoop EcoSystem
Spark Architecture and EcoSystem
DataBricks SignUp
Create DataBricks Notebook
Download Spark and Dependencies
Java Setup on Window
Python Setup on Window
Spark Setup on Window
Hadoop Setup on Window
Runing Spark on Window
Java Download on MAC
01:52
Installing JDK on MAC
01:01
Setting Java Home on MAC
03:02
Java check on MAC
01:18
Installing Python on MAC
01:13
Setup Spark on MAC
04:18
Which of the following statement is True
1 question
Which of the following is not a part of spark ecosystem?
1 question
Spark RDDs
08:28
Creating Spark RDD
11:00
Running Spark Code Locally
10:16
RDD stands for:
1 question
RDD is created by using:
1 question
RDD Map (Lambda)
11:08
RDD Map (Simple Function)
09:37
Quiz (Map)
01:23
Solution 1 (Map)
06:37
Solution 2 (Map)
04:01
RDD FlatMap
10:13
RDD Filter
08:02
Quiz (Filter)
01:37
Solution (Filter)
16:19
RDD Distinct
06:24
RDD GroupByKey
17:02
RDD ReduceByKey
13:46
Quiz (Word Count)
01:02
Solution (Word Count)
15:07
RDD (Count and CountByValue)
07:11
RDD (saveAsTextFile)
15:30
RDD (Partition)
18:06
Finding Average-1
15:03
Finding Average-2
07:09
Quiz (Average)
01:29
Solution (Average)
11:25
Finding Min and Max
10:18
Quiz (Min and Max)
00:57
Solution (Min and Max)
06:13
Project Overview
02:26
Total Students
03:40
Total Marks by Male and Female Student
06:51
Total Passed and Failed Students
04:49
Total Enrollments per Course
05:06
Total Marks per Course
03:13
Average marks per Course
12:45
Finding Minimum and Maximum marks
03:50
Average Age of Male and Female Students
05:48
Introduction to Spark DFs
08:08
Creating Spark DFs
10:34
DF stands for:
1 question
DF is created by using:
1 question
Spark Infer Schema
07:48
Spark Provide Schema
08:28
Create DF from Rdd
08:21
Rectifying the Error
05:17
Select DF Colums
11:49
Spark DF withColumn
19:46
Spark DF withColumnRenamed and Alias
06:12
Spark DF Filter rows
16:05
Quiz (select, withColumn, filter)
01:26
Solution (select, withColumn, filter)
10:19
Spark DF (Count, Distinct, Duplicate)
10:56
Quiz (Distinct, Duplicate)
00:45
Solution (Distinct, Duplicate)
05:19
Spark DF (sort, orderBy)
06:24
Quiz (sort, orderBy)
01:55
Solution (sort, orderBy)
09:14
Spark DF (Group By)
12:30
Spark DF (Group By - Multiple Columns and Aggregations)
10:37
Spark DF (Group By -Visualization)
13:25
Spark DF (Group By - Filtering)
11:08
Quiz (Group By)
00:52
Solution (Group By)
07:50
Quiz (Word Count)
00:54
Solution (Word Count)
04:39
Spark DF (UDFs)
08:34
Quiz (UDFs)
01:30
Solution (UDFs)
08:09
Solution (Cache and Presist)
07:30
Spark DF (DF to RDD)
07:24
Spark DF (Spark SQL)
06:16
Spark DF (Write DF)
10:45
Project Overview
02:11
Project (Count and Select)
04:11
Project (Group By)
04:26
Project (Group By, Aggregations and Order By)
05:03
Project (Filtering)
08:20
Project (UDF and WithColumn)
06:11
Project (Write)
03:17
Collaborative filtering
02:31
Utility Matrix
04:04
Explicit and Implicit Ratings
04:15
Expected Results
03:09
Dataset
06:38
Joining Dataframes
06:42
Train and Test Data
06:26
ALS model
05:56
Hyperparameter tuning and cross validation
08:24
Best model and evaluate predictions
04:13
Recommendations
10:43
Introduction to Spark Streaming
04:46
Spark Streaming with RDD
04:25
Spark streaming is used to:
1 question
Spark Streaming Context
05:09
Spark Streaming Reading Data
05:18
Spark Streaming Cluster Restart
04:00
Spark Streaming RDD Transformations
07:41
Which statement is true about SparkContext and StreamingContext:
1 question
Spark Streaming DF
08:22
Spark Streaming Display
05:14
Spark Streaming DF Aggregations
05:35
Introduction to ETL
04:58
We can perform ETL using PySpark:
1 question
ETL stands for:
1 question
ETL pipeline Flow
02:20
Data set
02:35
Extracting Data
03:20
Transforming Data
14:15
Loading data (Creating RDS-I)
09:07
Load data (Creating RDS-II)
02:49
RDS Networking
05:30
Downloading Postgres
01:16
Installing Postgres
01:53
Connect to RDS thorugh PgAdmin
02:35
Loading Data
15:40
Introduction to Project
01:48
Project Architecture
15:43
In this project we are going to implement:
1 question
The cloud service DMS will be used to:
1 question
Creating RDS MySql instance
09:27
Creating S3 Bucket
03:32
Creating DMS Source Endpoint
05:37
Creating DMS Destination Endpoint
05:35
Creating DMS Instance
02:42
MySql WorkBench
01:16
Connecting with RDS and Dumping Data
06:02
Quering RDS
01:57
DMS Full Load
08:30
DMS Replication Ongoing
06:03
Stoping Instances
01:45
Glue Job (Full Load)
08:28
Glue Job (Change Capture)
03:50
Glue Job (CDC)
15:26
Creating Lambda Function and Adding Trigger
06:46
Checking Trigger
05:21
Getting S3 file name in Lambda
04:28
Creating Glue Job
05:24
Adding Invoke for Glue Job
04:49
Testing Invoke
04:59
Writing Glue Shell Job
05:51
Full Load Pipeline
06:41
Change Data Capture Pipeline
07:12